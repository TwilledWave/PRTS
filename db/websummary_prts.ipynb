{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5767a8-2b30-417c-bd8e-c83fd1b31270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script summarizes the webpage from URL; writes its page content, meta data into a vector db\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "import configparser, os, re\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./keys.ini')\n",
    "os.environ['GOOGLE_API_KEY'] = config['GOOGLE']['GOOGLE_API_KEY']\n",
    "os.environ['GOOGLE_CSE_ID'] = config['GOOGLE']['GOOGLE_CSE_ID']\n",
    "openai_api_key = config['OPENAI']['OPENAI_API_KEY']\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#web loader and split\n",
    "def web_loader_docs(link:str):\n",
    "    #input: link of the web page url\n",
    "    #web loader\n",
    "    loader = WebBaseLoader(link)\n",
    "    docs = loader.load()\n",
    "    #splitter\n",
    "    #text_splitter = RecursiveCharacterTextSplitter(chunk_size = 25000, chunk_overlap = 500)\n",
    "    #docs = text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "\n",
    "\n",
    "#story summary chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
    "#summary the story dialogue from main page content of the URL\n",
    "def story_summary(docs):\n",
    "    #input: docs of the web page\n",
    "    # Define LLM chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "    # Map\n",
    "    map_template = \"\"\"Summarize the dialogue in the docs.\n",
    "        {docs}\n",
    "        只输出中文。只输出总结，不需要评论故事。\n",
    "        输出:\"\"\"\n",
    "    map_prompt = PromptTemplate.from_template(map_template)\n",
    "    map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "    \n",
    "    # Reduce\n",
    "    reduce_template = \"\"\"依次陈列这几段故事情节。\n",
    "        {doc_summaries}\n",
    "        只输出中文。只输出故事，不需要评论故事。不要输出重复片段!\n",
    "        输出:\"\"\"\n",
    "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "    # Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    "    )\n",
    "    # Combines and iteravely reduces the mapped documents\n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `StuffDocumentsChain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into.\n",
    "        token_max=6000,\n",
    "    )\n",
    "\n",
    "    # Combining documents by mapping a chain over them, then combining results\n",
    "    map_reduce_chain = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"docs\",\n",
    "        # Return the results of the map steps in the output\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    #return the summary from the map and reduce procedure\n",
    "    return map_reduce_chain.run(docs)\n",
    "\n",
    "#use one 1 chain to summary the story dialogue from main page content of the URL\n",
    "def story_summary_stuff(docs):\n",
    "    #input: docs of the web page\n",
    "\n",
    "    # Define prompt\n",
    "    prompt_template = \"\"\"Summarize the dialogue in the text。\n",
    "    \"{text}\"\n",
    "    只输出中文。只输出故事，不需要评论故事。不要输出重复片段!\n",
    "    输出:\"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Define LLM chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # Define StuffDocumentsChain\n",
    "    stuff_chain = StuffDocumentsChain(\n",
    "        llm_chain=llm_chain, document_variable_name=\"text\"\n",
    "    )\n",
    "    \n",
    "    return stuff_chain.run(docs)\n",
    "\n",
    "#summarize a web page from scappy meta data\n",
    "def websummary_meta(meta:dict, overwrite = False, runlm = True, limit = \"\"):\n",
    "    #input: meta data dictionary of the target page\n",
    "    link = meta['source']\n",
    "    #meta['characters'] = ','.join(meta['characters'])\n",
    "    if (meta['stage'] == None):\n",
    "        meta['stage'] = \"\"\n",
    "    if not(limit in meta['stage']):\n",
    "        meta['stage'] = limit + \"-\" + meta['stage']\n",
    "    #load vector db for summary data\n",
    "    from langchain.embeddings import OpenAIEmbeddings\n",
    "    from langchain.vectorstores import Chroma\n",
    "    db = Chroma(persist_directory=\"./cndb\", embedding_function=OpenAIEmbeddings())\n",
    "    #get the db existing id set\n",
    "    tmp = db.get()['ids']\n",
    "    this_db_list = [x.split(\"_\")[0] for x in tmp]\n",
    "    this_db_set = set(this_db_list)\n",
    "    #check whether the hash link is in the db already\n",
    "    import hashlib\n",
    "    this_id = str(int(hashlib.sha1(link.encode(\"utf-8\")).hexdigest(), 16) % (10 ** 8))\n",
    "    story = \"None\"\n",
    "    if this_id in this_db_set:\n",
    "        if overwrite == False:\n",
    "            return(link+\" link already in the db, skip\");\n",
    "        else:\n",
    "            index = this_db_list.index(this_id)\n",
    "            story = db.get()['documents'][index]\n",
    "    \n",
    "    #load\n",
    "    docs_org = web_loader_docs(link)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 20000, chunk_overlap = 500)\n",
    "    docs = text_splitter.split_documents(docs_org)\n",
    "\n",
    "    #find CG page from the webpage\n",
    "    cg_link = get_cg(docs_org)\n",
    "    meta['cg'] = cg_link\n",
    "\n",
    "    #summarize the story\n",
    "    if runlm == True:\n",
    "        if len(docs) > 2:\n",
    "            story = story_summary(docs);\n",
    "        else:\n",
    "            story = story_summary_stuff(docs);\n",
    "    \n",
    "    #write to vector db\n",
    "    meta['indexed'] = True\n",
    "    from langchain.docstore.document import Document\n",
    "    output_doc = Document(page_content=story, metadata=meta);\n",
    "    db.add_documents([output_doc], ids = [this_id])\n",
    "    \n",
    "    # #load the database for original page text\n",
    "    # db2 = Chroma(persist_directory=\"./arkpage\", embedding_function=OpenAIEmbeddings())\n",
    "    # text_splitter = RecursiveCharacterTextSplitter(chunk_size = 5000, chunk_overlap = 0)\n",
    "    # docs2 = text_splitter.split_documents(docs_org)\n",
    "    # this_list =[this_id + \"_\" + \"{0:0=4d}\".format(x) for x in range(len(docs2))]\n",
    "    # output_docs2 =[Document(page_content=docs2[x].page_content, metadata=meta) for x in range(len(docs2))]\n",
    "    # db2.add_documents(output_docs2, ids = this_list)\n",
    "    \n",
    "    return(output_doc)\n",
    "\n",
    "#return CG link from the story\n",
    "def get_cg(docs):\n",
    "    #get the page link from dialogue\n",
    "    regex=r'(?<=\\[Image\\(image=\\\")[\\w_]+'\n",
    "    pics = re.findall(regex, docs[0].page_content)\n",
    "    if len(pics)==0:\n",
    "        return(\"\");\n",
    "    link = \"https://prts.wiki/w/%E6%96%87%E4%BB%B6:Avg_\"+pics[0]+\".png\"\n",
    "    print(link)\n",
    "    #get the 640px pic from the pic link\n",
    "    from urllib.request import urlopen\n",
    "    try:\n",
    "        html_page = urlopen(link).read()\n",
    "    except:\n",
    "        return(\"\");\n",
    "    pics = re.findall(r'https://[\\w./-]+',str(html_page))\n",
    "    if len(pics)==0:\n",
    "        return(\"\");\n",
    "    if len(pics)>3:\n",
    "        if '640' in pics[2]:\n",
    "            return(pics[2]);\n",
    "    return(pics[0]);\n",
    "\n",
    "#main function, summarize a list of web pages from the scapy json\n",
    "def run_scapy(file = \"quotes.json\", limit = \"\", overwrite = False, runlm = True):\n",
    "    import json, time\n",
    "    # Opening JSON file\n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        scapy_list = json.load(f)\n",
    "\n",
    "    for l in range(len(scapy_list)):\n",
    "        if (limit in scapy_list[l][\"stage\"]) | (limit in scapy_list[l][\"source\"]):\n",
    "            print(scapy_list[l])\n",
    "            print(websummary_meta(scapy_list[l], overwrite, runlm, limit))\n",
    "            scapy_list[l]['indexed'] = True;\n",
    "            with open(file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "                outfile.write(json.dumps(scapy_list))\n",
    "            time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51c7dd8-3de1-4805-96d4-512be4980506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://prts.wiki/index.php?title=RO3-BEG/NBT&action=edit', 'indexed': True, 'stage': 'RO-序章', 'cg': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='None' metadata={'source': 'https://prts.wiki/index.php?title=RO3-BEG/NBT&action=edit', 'indexed': True, 'stage': 'RO3-RO-序章', 'cg': ''}\n",
      "{'source': 'https://prts.wiki/index.php?title=RO3-END-1/NBT&action=edit', 'indexed': True, 'stage': 'RO-越过群山', 'cg': 'https://prts.wiki/images/thumb/7/7c/Avg_pic_rogue_3_31.png/640px-Avg_pic_rogue_3_31.png'}\n",
      "https://prts.wiki/w/%E6%96%87%E4%BB%B6:Avg_pic_rogue_3_31.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='None' metadata={'source': 'https://prts.wiki/index.php?title=RO3-END-1/NBT&action=edit', 'indexed': True, 'stage': 'RO3-RO-越过群山', 'cg': 'https://prts.wiki/images/thumb/7/7c/Avg_pic_rogue_3_31.png/640px-Avg_pic_rogue_3_31.png'}\n",
      "{'source': 'https://prts.wiki/index.php?title=RO3-END-2/NBT&action=edit', 'indexed': True, 'stage': 'RO-直至冬夜降临', 'cg': 'https://prts.wiki/images/thumb/5/57/Avg_pic_rogue_3_32.png/640px-Avg_pic_rogue_3_32.png'}\n",
      "https://prts.wiki/w/%E6%96%87%E4%BB%B6:Avg_pic_rogue_3_32.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='None' metadata={'source': 'https://prts.wiki/index.php?title=RO3-END-2/NBT&action=edit', 'indexed': True, 'stage': 'RO3-RO-直至冬夜降临', 'cg': 'https://prts.wiki/images/thumb/5/57/Avg_pic_rogue_3_32.png/640px-Avg_pic_rogue_3_32.png'}\n",
      "{'source': 'https://prts.wiki/index.php?title=RO3-END-3/NBT&action=edit', 'indexed': True, 'stage': 'RO-自深处的一瞥', 'cg': ''}\n",
      "https://prts.wiki/w/%E6%96%87%E4%BB%B6:Avg_pic_rogue_3_33.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='None' metadata={'source': 'https://prts.wiki/index.php?title=RO3-END-3/NBT&action=edit', 'indexed': True, 'stage': 'RO3-RO-自深处的一瞥', 'cg': 'https://prts.wiki/images/thumb/6/6a/Avg_pic_rogue_3_33.png/640px-Avg_pic_rogue_3_33.png'}\n",
      "{'source': 'https://prts.wiki/index.php?title=RO3-END-4/NBT&action=edit', 'indexed': True, 'stage': 'RO-终始', 'cg': 'https://prts.wiki/images/thumb/3/39/Avg_pic_rogue_3_35.png/640px-Avg_pic_rogue_3_35.png'}\n",
      "https://prts.wiki/w/%E6%96%87%E4%BB%B6:Avg_pic_rogue_3_35.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n",
      "Delete of nonexisting embedding ID: 176\n",
      "Delete of nonexisting embedding ID: 177\n",
      "Delete of nonexisting embedding ID: 178\n",
      "Delete of nonexisting embedding ID: 179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='None' metadata={'source': 'https://prts.wiki/index.php?title=RO3-END-4/NBT&action=edit', 'indexed': True, 'stage': 'RO3-RO-终始', 'cg': 'https://prts.wiki/images/thumb/3/39/Avg_pic_rogue_3_35.png/640px-Avg_pic_rogue_3_35.png'}\n"
     ]
    }
   ],
   "source": [
    "run_scapy(file = \"prts010924.json\", limit = \"RO3\", overwrite = True, runlm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6b83611-ac5a-4236-b5d7-4d3d477317bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "db = Chroma(persist_directory=\"./cndb\", embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "798611c0-b9f5-4e90-84f6-9ab2da9331ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cg': 'https://prts.wiki/images/thumb/f/f6/Avg_32_i03.png/640px-Avg_32_i03.png',\n",
       " 'indexed': True,\n",
       " 'source': 'https://prts.wiki/index.php?title=13-6_%E5%85%B8%E8%8C%83%E4%B9%8B%E5%90%8D/END&action=edit',\n",
       " 'stage': '13-6 典范之名 行动后'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get()['metadatas'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ada65f5-de2b-4013-8303-21bfa8d160a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://prts.wiki/index.php?title=ZT-1_%E6%B8%85%E5%94%B1%E2%80%9C%E6%99%B4%E7%A9%BA%E4%B9%8B%E6%AD%8C%E2%80%9D/BEG&action=edit\"\n",
    "res = web_loader_docs(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "894a5cf9-338b-48d4-a54e-236ed3ad5edd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58637907\n",
      "https://prts.wiki/index.php?title=TG-ST1_%E7%9B%96%E4%B8%8D%E4%BD%8F%E7%9A%84%E9%94%85%E7%9B%96/NBT&action=edit\n",
      "故事发生在一个小镇上，阿兰娜和小锅盖是好朋友。他们一起在阿兰娜的运载车上工作，准备离开这个小镇。阿兰娜做了很多菜，为了让菜保持热，她敲碗提醒它们慢慢变凉。他们聊了很多关于食物的话题，然后听到了奇怪的声音。他们发现是一个陌生人在敲门，他们决定去看看。在路上，小锅盖不小心推车撞到了一个人，但幸运的是没有受伤。他们来到了一个百货店，阿兰娜想买一只沙地兽，而小锅盖想卖掉一些东西。百货店老板同意帮助他们，但他们需要找到特定型号的安全阀。然而，他们没有找到合适的阀门，他们决定继续寻找。故事结束时，他们决定分工，继续努力寻找所需的物品。\n",
      "\n",
      "在对话中，小锅盖想要找到一些东西，请求百货店老板帮忙看着推车。百货店老板询问阿兰娜是否还需要购买其他东西。沉默寡言的顾客没有回答。阿兰娜和小查理之间发生了一些争执，他们讨论了阿兰娜照顾小孩的问题。阿兰娜解释了她为什么要照顾小孩，并威胁要把球踢到小查理的脸上。他们继续讨论阿兰娜是否会回来，最后决定明天再谈。小锅盖去买东西，回来后发现阿兰娜已经完成了工作，并和叔叔们打球。阿兰娜解释了她为什么能这么快完成工作。他们讨论了剩下的工作和明天的行程。小锅盖提议帮忙交《停运报告书》，以便阿兰娜能多和朋友们聊一会儿。最后，小锅盖遇到一个畏畏缩缩的乘客，他们讨论了乘车时间和等待的人。小锅盖最后决定帮助乘客等待的人。\n",
      "\n",
      "在这段对话中，小锅盖正在等待进入办公室提交文件，但是时间很紧迫。她和一位名叫雷厉风行的女性聊天，女性抱怨人太多，办事效率低下。小锅盖担心文件来不及交，但是女性表示可以帮她交。小锅盖犹豫不决，但最终还是把文件交给了女性。之后，小锅盖赶上了车，但她心里还有些不安。最后，她听到广播说车要去咧嘴谷，但突然发现车被劫持了。\n",
      "30681391\n",
      "https://prts.wiki/index.php?title=TG-ST2_%E4%B8%8D%E5%9B%9E%E5%A4%B4%E7%9A%84%E8%BD%A6%E8%BE%99/NBT&action=edit\n",
      "这段对话发生在一个运载车上，阿兰娜是驾驶员，而劫车人是乘客。阿兰娜开始感叹自己只是一团风滚草，而劫车人则对她保持沉默。他们之间发生了一些争执，但最终达成了一种妥协。在车上的其他乘客也参与了对话，讨论了劫车人的动机和车上的安全问题。随后，运载车遇到了拥堵，阿兰娜希望能够利用这个机会夺回控制权。然而，劫车人提醒她车外的情况可能不太妙，有可能是在躲避天灾或其他危险。最后，运载车被拦下进行例行检查，阿兰娜试图反抗，但最终还是下了车。\n",
      "\n",
      "阿兰娜和劫车人被安保人员拦下，被要求下车接受调查。阿兰娜试图为乘客辩护，但安保人员态度强硬。阿兰娜注意到车上有两个隐藏的人，但她没有透露。安保人员要求检测设备响了的人下车，但突然被弩箭射击打断。劫车人趁机解救了小锅盖，并与阿兰娜一起逃离。他们决定冲关逃跑，但车身受损，风和寒冷的空气进入车内。阿兰娜发现劫车人也是感染者，但她决定暂时放下身份的区别，大家一起劫车。他们决定前往咧嘴谷，但需要补给燃料。劫车人自称莱伊，他们一起决定去移动平台补给。\n",
      "\n",
      "阿兰娜和劫车人在讨论还车时要如何向公司交代。阿兰娜问劫车人叫什么名字，劫车人回答他们在矿场都叫他莱伊。阿兰娜建议称呼他为“劫车的”。阿兰娜好奇劫车人为什么要去咧嘴谷，猜测可能是因为那里有宝藏。劫车人回答他要去找一个巨大的阴影，它会散发光线并且会说话。阿兰娜对此感到惊讶。然后出现了一个鬼怪，阿兰娜惊恐地喊出声来。\n",
      "65004030\n",
      "https://prts.wiki/index.php?title=TG-ST3_%E7%8B%82%E5%A5%94%E7%9A%84%E7%93%B6%E6%A0%91/NBT&action=edit\n",
      "这段对话发生在一个运载车上，杰里和阿兰娜讨论是否要经过大风滩。杰里提到了大风滩的危险和可能导致车辆损坏的因素。阿兰娜不太在意，她认为他们只需要伪装成一辆普通的运货车就可以了。他们还讨论了保险和阿兰娜的过去经历。之后，他们遇到了一些穿制服的工作人员，但最终顺利通过了检查。\n",
      "\n",
      "在另一段对话中，杰里和莱伊讨论了他们的背景和目的地。最后，他们遇到了一个陌生的女性，她似乎对他们有所怀疑。\n",
      "\n",
      "在对话中，莱伊和穿制服的工作人员讨论了一些事情，包括笔录的作废和莱伊对于月度促销杂志的疑问。接着，阿米娅和暴行姐姐谈论了雷姆必拓和阿米娅的回忆。之后，阿米娅和暴行姐姐来到了雷姆必拓，回忆起了童年的一些事情。接着，他们遇到了一些陌生人，一起逃离了追捕。最后，阿米娅和陌生女性讨论了逃跑的计划。\n",
      "\n",
      "在这段对话中，莱伊告诉阿兰娜他无法拿武器，因为物资补给清单上列的东西太多。阿兰娜表示希望不再出事，因为检查站的事已经够难受的了。接着，杰里和一位陌生的女性谈论了逃婚和家庭的话题。杰里向陌生女性提出了一个关于保险的问题，希望她成为他购买保险的受益人。陌生女性同意了，并表示这种方式更符合她的想法。随后，他们继续谈论了家庭的经验和长辈的安排。最后，小锅盖突然消失了，阿兰娜怀疑她可能在动力室。\n",
      "39345704\n",
      "https://prts.wiki/index.php?title=TG-ST4_%E8%90%BD%E5%AE%9A%E7%9A%84%E9%94%A4%E5%AD%90/NBT&action=edit\n",
      "阿米娅和暴行在雷姆必拓的荒野上旅行，遇到了一辆冒烟的运载车，车上有一位叫小锅盖的感染者。阿兰娜是小锅盖的照顾者，试图治疗小锅盖的矿石病，但方法无效。阿米娅使用法术帮助小锅盖入睡，减轻她的痛苦。阿米娅问博士是否还需要她的帮助，博士回答不需要。阿兰娜问小温米是否没问题了，阿米娅回答潜意识的施术行为停止了，但还需要观察一段时间。阿兰娜感谢他们救了小温米，阿米娅建议前往罗德岛办事处做更全面的检查。阿兰娜找到了名片上的标志，是挖掘机挖斗的标志。阿米娅提到如果雷姆必拓的企业能提升对矿石病防护的意识，患者可能不会遇到危险。阿兰娜同意驾驶车前往移动城市。阿兰娜说车情况特殊，无法折返，暴行提到前面是无人区，阿兰娜说他们要去找巨兽。小锅盖问能不能跟着一起找巨兽，莱伊没有回答。阿米娅说她听过巨兽的故事，博士回忆起以前讲过的童话故事。暴行问博士是否还醒着，博士说他在想起一些旧书里的故事。暴行向博士要过一个承诺，希望博士能对阿米娅好。暴行问博士是否需要他的帮助，博士说有需要会告诉他。暴行提到阿米娅一直在那边坐着，问博士是否认为她是潜在危险。\n",
      "12252675\n",
      "https://prts.wiki/index.php?title=TG-ST5_%E5%92%A7%E5%98%B4%E7%9A%84%E7%9F%BF%E4%BA%95/NBT&action=edit\n",
      "莱伊每天早上去矿场工作，有一只沙地兽作为伴侣。矿井发生毒气泄漏和结构破坏，莱伊和沙地兽勇敢面对困难。他们发现了一个充满活着的沙地兽的地方，带来希望和勇气。莱伊误认了一个沙地兽，阿兰娜找到他们并询问原因。阿兰娜发现周围有很多沙地兽，询问博士是否能理解探测器的数据。博士建议快回到车上离开。阿兰娜意识到可能有天灾即将来临，但阿米娅认为还来得及离开。他们决定尽快离开并行动。逃离过程中遇到困难，但最终成功逃离。莱伊注意到周围一切都被摧毁，阿兰娜抱怨他们跑得太慢。莱伊意识到自己可以成为他们的庇护所，并带领他们前进。他们找到庇护所，但莱伊被困在岩石中。最后，他们发现了一个巨兽，莱伊意识到这就是他一直在寻找的光。\n",
      "26204623\n",
      "https://prts.wiki/index.php?title=TG-ST6_%E8%A2%AB%E8%B8%A9%E4%BD%8F%E7%9A%84%E5%BD%B1%E5%AD%90/NBT&action=edit\n",
      "阿兰娜和小锅盖讨论旅行经历和博士动机。阿兰娜提到被劫持的经历和对博士的好奇。杰里加入对话，询问是否找到莱伊所说的东西。阿兰娜解释没有找到，并描述莱伊的奇怪行为。继续讨论旅途中看到的事物。小锅盖和暴行姐讨论学习法杖进展，遇到阿兰娜和杰里，提到婚礼和小货车。决定等待阿兰娜一起去罗德岛。继续讨论法杖使用，遇到阿兰娜，带来生态箱作为礼物。阿米娅和博士讨论咧嘴谷和莱伊所说的巨兽。遇到莱伊，表达感激并愿意加入罗德岛。莱伊喜欢罗德岛的身份牌，阿米娅表示罗德岛可以成为她的家。莱伊问为什么向往亮光，回忆在咧嘴谷遇到巨兽和亮光的经历。阿米娅看见罗德岛被挖掘出来的景象，描述罗德岛的行进和希望。问莱伊是通过谁的眼睛看到这一切的，莱伊回答是自己的幻觉。阿米娅说信任博士，并描述博士的愿望和罗德岛的定义。阿米娅问博士是否相信她，并表示愿意努力。\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=\"./cndb\")\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=os.environ['OPENAI_API_KEY'],\n",
    "                model_name=\"text-embedding-ada-002\"\n",
    "            )\n",
    "db = client.get_collection(name=\"langchain\", embedding_function=openai_ef)\n",
    "ids = []\n",
    "this = db.get()\n",
    "for id in range(len(this['ids'])):\n",
    "    if \"TG-\" in this['metadatas'][id]['source']:\n",
    "        ids.append(this['ids'][id])\n",
    "        print(this['ids'][id])\n",
    "        print(this['metadatas'][id]['source'])\n",
    "        print(this['documents'][id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2d40dd-7883-4610-b119-67f4c10582e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db.delete(ids=ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988945e-85e7-4f22-99d5-c198cc23608f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
