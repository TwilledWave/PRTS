{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05e78957-37e2-45cc-8c42-023de8b5c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "import requests\n",
    "\n",
    "HOST = 'localhost:5000'\n",
    "URI = f'http://{HOST}/api/v1/generate'\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        if isinstance(stop, list):\n",
    "            stop = stop + [\"\\n###\",\"\\nObservation:\"]\n",
    "\n",
    "        response = requests.post(\n",
    "            URI,\n",
    "            json={\n",
    "                \"prompt\": prompt,\n",
    "                \"temperature\": 0.1,\n",
    "                \"max_new_tokens\": 256,\n",
    "                \"early_stopping\": True,\n",
    "                \"stopping_strings\": stop,\n",
    "                'do_sample': True,\n",
    "                'top_p': 0.1,\n",
    "                'typical_p': 1,\n",
    "                'repetition_penalty': 1.18,\n",
    "                'top_k': 40,\n",
    "                'min_length': 0,\n",
    "                'no_repeat_ngram_size': 0,\n",
    "                'num_beams': 1,\n",
    "                'penalty_alpha': 0,\n",
    "                'length_penalty': 1,\n",
    "                'seed': -1,\n",
    "                'add_bos_token': True,\n",
    "                'truncation_length': 8192,\n",
    "                'ban_eos_token': False,\n",
    "                'skip_special_tokens': True,\n",
    "            },\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()['results'][0]['text']\n",
    "  \n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {}\n",
    "\n",
    "llm = CustomLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd39a748-1998-4064-8cac-c42845b40169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeLLM(LLM):\n",
    "    n: int\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        return prompt[: self.n]\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"n\": self.n}\n",
    "\n",
    "llm_fake = FakeLLM(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea5767a8-2b30-417c-bd8e-c83fd1b31270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script summarizes the webpage from URL; writes its page content, meta data into a vector db\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "import configparser, os\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./keys.ini')\n",
    "os.environ['GOOGLE_API_KEY'] = config['GOOGLE']['GOOGLE_API_KEY']\n",
    "os.environ['GOOGLE_CSE_ID'] = config['GOOGLE']['GOOGLE_CSE_ID']\n",
    "openai_api_key = config['OPENAI']['OPENAI_API_KEY']\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#web loader and split\n",
    "def web_loader_docs(link:str):\n",
    "    #input: link of the web page url\n",
    "    #web loader\n",
    "    loader = WebBaseLoader(link)\n",
    "    docs = loader.load()\n",
    "    #splitter\n",
    "    #text_splitter = RecursiveCharacterTextSplitter(chunk_size = 25000, chunk_overlap = 500)\n",
    "    #docs = text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "\n",
    "\n",
    "def story_summary(docs):\n",
    "    #input: docs of the web page\n",
    "    # Define LLM chain\n",
    "    #llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "    # Map\n",
    "    map_template = \"\"\"The following are documents containing dialogues\n",
    "        {docs}\n",
    "        Write a detailed summary of the dialogues in each. ONLY summarize the dialogues.\n",
    "        Output:\"\"\"\n",
    "    map_prompt = PromptTemplate.from_template(map_template)\n",
    "    map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "    \n",
    "    # Reduce\n",
    "    reduce_template = \"\"\"\n",
    "        {doc_summaries}\n",
    "        \"\"\"\n",
    "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "    reduce_chain = LLMChain(llm=llm_fake, prompt=reduce_prompt)\n",
    "    # Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    "    )\n",
    "    # Combines and iteravely reduces the mapped documents\n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `StuffDocumentsChain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into.\n",
    "        token_max=6000,\n",
    "    )\n",
    "\n",
    "    # Combining documents by mapping a chain over them, then combining results\n",
    "    map_reduce_chain = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"docs\",\n",
    "        # Return the results of the map steps in the output\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    #return the summary from the map and reduce procedure\n",
    "    return map_reduce_chain.run(docs)\n",
    "\n",
    "#use one 1 chain to summary the story dialogue from main page content of the URL\n",
    "def story_summary_stuff(docs):\n",
    "    #input: docs of the web page\n",
    "\n",
    "    # Define prompt\n",
    "    prompt_template = \"\"\"Write a detailed summary of the dialogue.\n",
    "    \"{text}\"\n",
    "    OUtput:\"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Define LLM chain\n",
    "    #llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # Define StuffDocumentsChain\n",
    "    stuff_chain = StuffDocumentsChain(\n",
    "        llm_chain=llm_chain, document_variable_name=\"text\"\n",
    "    )\n",
    "    \n",
    "    return stuff_chain.run(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6b83611-ac5a-4236-b5d7-4d3d477317bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = \"https://arknights.fandom.com/wiki/10-8/Story\"\n",
    "docs_org = web_loader_docs(link)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 5000, chunk_overlap = 500)\n",
    "docs = text_splitter.split_documents(docs_org)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ada65f5-de2b-4013-8303-21bfa8d160a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        \\n        \\n\\n\\n\\nAdministrators, policies and guidelines\\nRecent blog posts\\n\\n\\n\\n\\nThe following are documents containing dialogues:\\n\\n\\n\\nAdmins\\n\\n\\n\\t* Episode 1\\n\\n\\n\\n\\n\\nVictoria has lost another fine soldier. A little girl has lost her father. How many more must we lose before we finally see the end of this tragedy?\\nThe team got back a while ago. They didn\\'t find any medicine. Salley\\'s family lived in County Ascarat. Blake up his belongings, please. Once the war is over, we\\'ll pay his family a visit. He left nothing behind. No story to tell. We have to go on this journey still. His daughter will want to hear his story. Horn apologized to me. Said \"Sorry, Lieutenant, but you must live on.\" Soldier said. Victoria understands. It\\'s harder to live. A Victorian soldier owes an apology. The state of Londonium is their home, but it\\'s become a prison. They want to keep marching down this road because Clovis gave them hope.\\nClovis marked eight probable locations on the map. There are no settlements near any of them. They\\'re located near the highway that leads to Central Londonium, which facilitates Sark movement around the city and none of them are connected to the plate they\\'re\\n\\n\\n        \\n\\n\\n        The Sark are opposing faction wants to keep their existence secret from Self-Salvation Corps, and want Lady Heidi Thomson back. They have captured Messenger who has important information about Victoria\\'s whereabouts.\\n        '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_summary(docs[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7831fbf-7ee0-496a-bc05-368ee27e4b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Administrators\\n\\n\\n\\n\\nPolicies and guidelines\\n\\n\\n\\n\\nRecent blog posts\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\nin:\\nStories, Episode 10 \\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t10-8 story\\t\\t\\t\\t\\n< 10-8\\n\\n\\n\\n\\n \\n\\n\\t\\t\\t\\t\\t\\tSign in to edit\\t\\t\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tView history\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tTalk (0)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOperationGuideStory\\n\\n\\nPrevious 10-7\\n\\nNext 10-9\\n\\n\\nCharacters\\n\\n\\nDoctor Amiya Horn Rockrock Clovisia Hoederer Mandragora Self-Salvation Corps Soldier Victorian Soldier Dublinn Soldier Sarkaz Mercenary ???\\n\\n\\nBackgrounds\\n\\n\\n1 2 3\\n\\nAfter operation“Horn loses another comrade and decides to rescue all the remaining soldiers who have been taken prisoners by the Sarkaz. At the same time, Rhodes Island and the Self-Salvation Corps also plan their own operation to rescue Messenger Heidi Thomson, who has been captured by the Sarkaz.”\\n\\n\\n<Background 1>\\n\\n\\nSarkaz Mercenary\\n\\nBoss, you were right. We lost them.Those rebels... Crafty little sand beasts, the lot of them. Just five seconds, and it\\'s like they all burrowed into the sand without a trace.\\n\\n\\nHoederer\\n\\nSure enough, and that\\'s why we shouldn\\'t waste our energy on them.Guard your position well, until they poke their heads out of their holes again.\\n\\n\\nSarkaz Mercenary\\n\\nSure. You\\'re the boss.\\n\\n\\n[The Sarkaz mercs leave as someone talks with Hoederer.]\\n\\n\\n???\\n\\nLooks like you found yourself a bunch of loyal subordinates, \"Boss.\"\\n\\n\\nHoederer\\n\\nThey think it\\'ll pay dividends. It\\'s good for morale.\\n\\n\\n???\\n\\nThey trust you too. I can tell. It\\'s far more than what a mercenary should afford another mercenary.\\n\\n\\nHoederer\\n\\nJust goes to show how effective Manfred\\'s plan is.\\n\\n\\n???\\n\\nYou think real highly of him. I almost forgot. You two are practically brothers from another mother these days, right? Just look at the mansion he gave you. The den alone is larger than your old backyard.\\n\\n\\nHoederer\\n\\nIt was a count\\'s estate. I killed its previous owner.\\n\\n\\n???\\n\\nDon\\'t tell me that\\'s weighing on your conscience.\\n\\n\\nHoederer\\n\\nHe was having afternoon tea at the time... His wife and their three children were sitting right in front of him.\\n\\n\\n???\\n\\nSure, this is nothing like the kind of work we used to take, but you\\'re the one who agreed to the job. Nothing to mourn when our consciences died so long ago.\\n\\n\\nHoederer\\n\\nThen let\\'s not ask these questions. Whatever it is you want to know, just take a look for yourself. Not like you don\\'t know already.\\n\\n\\n???\\n\\nIs you being under a lot of stress supposed to somehow make me feel better?Whatever. Let\\'s talk about something else. It\\'s not the time for us to find comfort in each other. I\\'m here because I have some advice for you—Pay attention to what\\'s under your feet.\\n\\n\\nHoederer\\n\\nYou mean...\\n\\n\\n???\\n\\nMercenaries aren\\'t all that trustworthy.If you don\\'t pay attention to the shadows when you walk, your efforts might just be all for naught.\\n\\n\\nHoederer\\n\\nIs that all you came here for?\\n\\n\\n???\\n\\nNo, that\\'s not all.What I really wanted to say is–After drifting around for so long, she\\'s on the road.\\n\\n\\n<Background fades out and in>\\n\\n\\nMandragora\\n\\nAre our men in position?\\n\\n\\nDublinn Soldier\\n\\nYes, all at that place per the Sarkaz\\'s orders.\\n\\n\\nMandragora\\n\\nDon\\'t be daft. I\\'m not talking about what the Sarkaz want us to do.\\n\\n\\nDublinn Soldier\\n\\nCaptain, are we really going to start this operation tonight? Are you sure we won\\'t...\\n\\n\\nMandragora\\n\\nYou trying to ask if we\\'ll fall into Manfred\\'s trap?Do you think I\\'m so stupid that I can\\'t tell what he\\'s trying to do?\\n\\n\\nDublinn Soldier\\n\\nNo, of course not... I wouldn\\'t dare to...\\n\\n\\nMandragora\\n\\nHe\\'s trying to test me, and I\\'ll let him test me.Our men are his to order around... but he doesn\\'t know how many of us there are.\\n\\n\\nDublinn Soldier\\n\\nSo, we still have to be the Sarkaz\\'s gatekeepers, then?\\n\\n\\nMandragora\\n\\nShut up.I hate putting it that way. It makes it sound as though we\\'re the Sarkaz\\'s... the Sarkaz\\'s...Gah, whatever. We just have to bear with it today. Once we\\'re done with this last thing, we\\'ll leave Londinium straight away.\\n\\n\\nDublinn Soldier\\n\\nW-Will we really? That\\'s wonderful news!Ever since I was a kid... I... I\\'ve always hated Londinium. My parents both came to this place and never went back...This city eats people!\\n\\n\\nMandragora\\n\\nRight, I don\\'t like it either. Have you ever seen another city like this? So many plates, so many tall towers, and so many sewers?Every time I smell that stench... The smell of grease on the nobles\\' dining tables, it makes me want to puke.And now we can finally leave.Get the word out, and put on your best performance tonight. Do not give Manfred anything he can use against us.And I want the ten best fighters to come with me.As for you, I want you to tail Manfred... You saw where he was heading, right?\\n\\n\\nDublinn Soldier\\n\\nYes, Captain.\\n\\n\\nMandragora\\n\\nGood.Tonight, I\\'ll rescue our \"spy.\"I\\'ve stayed here in Londinium for so long, I have to at least get one thing done before I can go home with my mind at ease, right?I... I won\\'t let our leader down again.\\n\\n\\n<Background 2>\\n\\n\\nVictorian Soldier\\n\\nHorn, you\\'re back!\\n\\n\\n[Horn walks in.]\\n\\n\\nHorn', metadata={'source': 'https://arknights.fandom.com/wiki/10-8/Story', 'title': '10-8 story | Arknights Wiki | Fandom', 'language': 'en'})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8e66c-0555-4627-90fb-375560204b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
