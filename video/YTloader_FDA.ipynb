{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffab1d33-677f-4138-bedc-d9019df6f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the question and comments in FDA meeting videos\n",
    "\n",
    "import configparser, os, re\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./keys.ini')\n",
    "os.environ['GOOGLE_API_KEY'] = config['GOOGLE']['GOOGLE_API_KEY']\n",
    "os.environ['GOOGLE_CSE_ID'] = config['GOOGLE']['GOOGLE_CSE_ID']\n",
    "openai_api_key = config['OPENAI']['OPENAI_API_KEY']\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f45c56b-32a2-440e-844e-67e970c73888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-1106-preview\")\n",
    "from langchain.docstore.document import Document\n",
    "import requests\n",
    "import re\n",
    "\n",
    "class CustomLLM2(LLM):\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        if isinstance(stop, list):\n",
    "            stop = stop + [\"\\n###\",\"\\nObservation:\",\"\\n问题\",\"\\nQuestion:\"]\n",
    "        HOST = 'localhost:5000'\n",
    "        URI = f'http://{HOST}/v1/chat/completions'\n",
    "\n",
    "        response = requests.post(\n",
    "            URI,\n",
    "            json={\n",
    "                \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                  }\n",
    "                ],\n",
    "                \"mode\": \"instruct\",\n",
    "                \"instruction_template\": \"Alpaca\",\n",
    "            },\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "  \n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {}\n",
    "\n",
    "#use one 1 chain to summary the story dialogue from main page content of the URL\n",
    "def story_summary_stuff(docs, prompt_template = \"\"):\n",
    "    #input: docs of the web page\n",
    "    from langchain.chains.llm import LLMChain\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "    # Define prompt\n",
    "    if prompt_template == \"\":\n",
    "        prompt_template = \"\"\"in the following subtitle, is it a specific question about clinical trial or patient?  \n",
    "        If \"No\",  only answers \"No\". Otherwise, summarize the question.\n",
    "\n",
    "        \"{subtitle}\"\n",
    "        \n",
    "        Output:\"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Define LLM chain\n",
    "    #llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # Define StuffDocumentsChain\n",
    "    stuff_chain = StuffDocumentsChain(\n",
    "        llm_chain=llm_chain, document_variable_name=\"subtitle\"\n",
    "    )\n",
    "    \n",
    "    return stuff_chain.run(docs)\n",
    "\n",
    "def get_sec(time_str):\n",
    "    \"\"\"Get seconds from time.\"\"\"\n",
    "    h, m, s = time_str.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "def save_snapshot(vid, time, path = \"./cache/FDA/\"):\n",
    "    import cv2\n",
    "    vidcap = cv2.VideoCapture(path+\"/video/\"+vid+\".mp4\")\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,int(time)*1000)      # just cue to <time> sec. position\n",
    "    success,image = vidcap.read()\n",
    "    if success:\n",
    "        cv2.imwrite(path+\"/image/\"+vid+\"/\"+str(time)+\".jpg\", image)     # save frame as JPEG file\n",
    "    return(path+\"/image/\"+vid+\"/\"+str(time)+\".jpg\");\n",
    "\n",
    "#search keyword and summarize the following sentences in the next 200 characters\n",
    "def search_keyword(srt, keyword = \"question\", next = 1000, prefix = \"\", limit = 3):\n",
    "    res = []; time_stamp = []; link = []; count = 0;\n",
    "    for m in re.finditer(keyword, srt):\n",
    "        text = srt[m.start():(m.start()+next)]\n",
    "        #get the first time stamp\n",
    "        time = re.findall('\\d+:\\d+:\\d+',text); time = time[0];\n",
    "        #remove time stamps\n",
    "        text = text.splitlines(); tmp = \"\";\n",
    "        for t in text:\n",
    "            if (len(t) > 5) & (not(\":\" in t)):\n",
    "                tmp = tmp + t + \"\\n\";\n",
    "        output_srt = Document(page_content=tmp, metadata=\"\");\n",
    "        answer = story_summary_stuff([output_srt])\n",
    "        if not(\"No\" in answer):\n",
    "            time_stamp.append(str(get_sec(time)));\n",
    "            link.append(prefix + str(get_sec(time)));\n",
    "            res.append(answer);\n",
    "            count += 1;\n",
    "            if count > limit:\n",
    "                break;\n",
    "            #res.append(prefix + str(get_sec(time)) + \"\\n\" + answer)\n",
    "            #print(tmp);print(res[-1]);\n",
    "    return time_stamp, link, res\n",
    "\n",
    "#youtube loader and return docs for the transcript with time stamps\n",
    "def loader(link:str, language=[\"zh\"], db_loc = \"./cache/YTDBT\", overwrite = False, path = \"./cache/FDA/\"):\n",
    "    #load video info from link\n",
    "    from langchain.document_loaders import YoutubeLoader\n",
    "    try:\n",
    "        loader = YoutubeLoader.from_youtube_url(\n",
    "            link, add_video_info=True, language=language\n",
    "        )\n",
    "        docs = loader.load()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return(None);\n",
    "        \n",
    "    #check whether the vid is already in the DB\n",
    "    this_id = docs[0].metadata['source']\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain.embeddings import OpenAIEmbeddings\n",
    "    db = Chroma(persist_directory=db_loc, embedding_function=OpenAIEmbeddings())\n",
    "    tmp = db.get()['ids']\n",
    "    #this_db_list = [x.split(\"_\")[0] for x in tmp]\n",
    "    #this_db_set = set(this_db_list)\n",
    "    this_db_set = set(tmp)\n",
    "    if this_id in this_db_set:\n",
    "        if overwrite == False:\n",
    "            return(link+\" link already in the db, skip\");\n",
    "    print(\"adding link \"+link);\n",
    "\n",
    "    #check whether the video has been downloaded\n",
    "    from pathlib import Path\n",
    "    if not(Path(path + \"/video/\" + this_id + \".mp4\")):\n",
    "        downloadYouTube(this_id, path = path + \"/video/\")\n",
    "    \n",
    "    #format the transcript into SRT\n",
    "    from youtube_transcript_api import YouTubeTranscriptApi\n",
    "    from youtube_transcript_api.formatters import SRTFormatter\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(docs[0].metadata['source'],languages=language)\n",
    "    formatter = SRTFormatter()\n",
    "    srt_formatted = formatter.format_transcript(transcript)\n",
    "    with open(\"./cache/Output.srt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(srt_formatted)\n",
    "\n",
    "    #get the summary of questions\n",
    "    time_stamp, link, res = search_keyword(srt_formatted, prefix = \"https://youtu.be/\"+docs[0].metadata['source']+\"?t=\")\n",
    "    from langchain.embeddings import OpenAIEmbeddings\n",
    "    from langchain.docstore.document import Document\n",
    "    output_doc = []; ids = [];\n",
    "    for i in range(len(res)):\n",
    "        snapshot_path = save_snapshot(this_id, time_stamp[i], path);\n",
    "        #write the summary into DB\n",
    "        meta = docs[0].metadata\n",
    "        meta['time'] = time_stamp[i];\n",
    "        meta['vlink'] = link[i];\n",
    "        meta['snapshot'] = snapshot_path\n",
    "        output_doc.append(Document(page_content=res[i], metadata=dict(meta)));\n",
    "        ids.append(meta['source']+\"_\"+str(meta['time']));\n",
    "    db.add_documents(output_doc, ids = ids)\n",
    "    return(output_doc)\n",
    "\n",
    "def downloadYouTube(vid, path = \"./cache/FDA/video/\"):\n",
    "    from pytube import YouTube\n",
    "    import os\n",
    "    videourl = \"https://www.youtube.com/watch?v=\"+vid\n",
    "    yt = YouTube(videourl)\n",
    "    yt = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    yt.download(output_path = path, filename = vid+\".mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5247c51-79be-4b88-8c64-5629cf53f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding link https://www.youtube.com/watch?v=-iHseGn2LhQ&list=PLweTl9OQEsJhOM8W6ZAigP7eJxBU_yQM6&index=1&ab_channel=U.S.FoodandDrugAdministration\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "#llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-1106-preview\")\n",
    "llm = CustomLLM2()\n",
    "res = loader(\"https://www.youtube.com/watch?v=-iHseGn2LhQ&list=PLweTl9OQEsJhOM8W6ZAigP7eJxBU_yQM6&index=1&ab_channel=U.S.FoodandDrugAdministration\",language=[\"en\",\"zh-Hant\"], db_loc = \"./cache/test\", overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "189251de-a48b-4ec0-a0e9-79f5ad85c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from json2html import *\n",
    "\n",
    "#output documents \n",
    "def run(doc:list, output = \"output.html\", path = \"./cache/FDA/\"):\n",
    "    tmp = [];\n",
    "    for k in range(len(doc)):\n",
    "        this = {\"link\": doc[k].metadata[\"vlink\"]+\".vlink\",\n",
    "                \"question\": doc[k].page_content,\n",
    "                \"snapshot\": \".image\"+doc[k].metadata[\"snapshot\"]\n",
    "               }\n",
    "        tmp.append(this);\n",
    "\n",
    "    html = json2html.convert(json = tmp)\n",
    "    #convert link\n",
    "    html = html.replace(\"http\",\"<a href=\\\"http\")\n",
    "    html = html.replace(\".vlink</td>\",\"\\\" target=\\\"_blank\\\">vlink</a>\")\n",
    "    #convert image\n",
    "    html = html.replace(\".image\",\"<img src=\\\"http\")\n",
    "    html = html.replace(\"jpg</td>\",\"jpg\\\"></td>\")\n",
    "\n",
    "    with open(path + output, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    \n",
    "    return(\"success: write query to output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfe68a50-a75b-4fbe-8b46-e7c4893b1693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'success: write query to output.html'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "532b6a8f-bfff-4e51-a27a-f324f2a30079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output documents \n",
    "def run(doc:list, output = \"output.html\", path = \"./cache/FDA/\"):\n",
    "    tmp = [];\n",
    "    for k in range(len(doc)):\n",
    "        this = {\"link\": doc[k].metadata[\"vlink\"]+\".vlink\",\n",
    "                \"question\": doc[k].page_content,\n",
    "                \"snapshot\": \".image\"+doc[k].metadata[\"snapshot\"]\n",
    "               }\n",
    "        tmp.append(this);\n",
    "    return(tmp)\n",
    "tmp = run(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d4a9db4-b277-4cad-8a7f-490d67466bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*some markdown* $\\phi$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "\\phi"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "![alt text](./cache/FDA/image/-iHseGn2LhQ/3616.jpg \"Title\")"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "tmp = \"![alt text](./cache/FDA/image/-iHseGn2LhQ/3616.jpg \\\"Title\\\")\"\n",
    "display(Markdown('*some markdown* $\\phi$'))\n",
    "# If you particularly want to display maths, this is more direct:\n",
    "display(Latex('\\phi'))\n",
    "display(Markdown(tmp))\n",
    "from markdown_pdf import MarkdownPdf\n",
    "pdf = MarkdownPdf(toc_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9782f6-756a-418a-a714-5f776c7c7021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f910c-335a-4f17-ad20-00814ca4ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(tmp)\n",
    "mk = df.to_markdown(index=False,tablefmt='fancy_grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767adc9-c10b-4ba0-b3ab-99d675d23c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
