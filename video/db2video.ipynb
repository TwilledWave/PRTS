{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc931a3a-60dc-4dec-8664-e69b0858f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiha\\anaconda3\\envs\\lang\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "C:\\Users\\shiha\\AppData\\Roaming\\Python\\Python311\\site-packages\\TTS\\api.py:77: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
      "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n",
      "C:\\Users\\shiha\\anaconda3\\envs\\lang\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from voice import *\n",
    "from voiceEN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4755c8c1-504d-44dd-95f4-fdaf8420b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mpy\n",
    "from moviepy.audio.AudioClip import AudioArrayClip\n",
    "\n",
    "def audio_fadein(clips,fade_in = 0.05):\n",
    "    final_clips = [\n",
    "        clip.audio_fadein(fade_in).audio_fadeout(fade_in)\n",
    "        for clip in clips\n",
    "    ]\n",
    "    return(final_clips)\n",
    "\n",
    "def text2audio(text:str, lang:str, audio = \"./cache/audio/1.wav\"):\n",
    "    #audio from text\n",
    "    text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
    "    if lang == \"en\":\n",
    "        tts.tts_to_file(text=text, file_path=audio)\n",
    "    else:\n",
    "        o3, o4 = tts_fn(text, lang = lang)\n",
    "        from scipy.io.wavfile import write\n",
    "        write(audio,o4[0],o4[1])\n",
    "    return()\n",
    "\n",
    "def text2video(text:str, lang:str, title = \"      \", folder = \"./cache/\", prefix = \"1\"):\n",
    "    #make audio\n",
    "    o4 = text2audio(text, lang = lang, audio = folder+\"audio/\"+prefix+\".wav\");\n",
    "    audio = mpy.AudioFileClip(folder+\"audio/\"+prefix+\".wav\")\n",
    "    #audio = AudioArrayClip(o4[1],fps = o4[0])\n",
    "    #make text\n",
    "    if lang == \"cn\":\n",
    "        txt_clip  = mpy.TextClip(text, fontsize = 20, color = \"white\", font = \"Microsoft-YaHei-&-Microsoft-YaHei-UI\")\n",
    "    else:\n",
    "        txt_clip  = mpy.TextClip(text, fontsize = 20, color = \"white\")\n",
    "    txt_clip = txt_clip.set_pos('bottom').set_duration(audio.duration)\n",
    "    title_clip  = mpy.TextClip(title, fontsize = 40, color = \"black\")\n",
    "    title_clip = title_clip.set_pos('top').set_duration(audio.duration)\n",
    "    #make video\n",
    "    clip = mpy.ImageClip(\"./cache/img.png\")\n",
    "    clip = clip.set_duration(audio.duration)\n",
    "    clip.audio = audio\n",
    "    clip  = mpy.CompositeVideoClip([clip, txt_clip, title_clip])\n",
    "    clip.fps = 12\n",
    "    #clip.write_videofile(\"./cache/clip.mp4\");\n",
    "    return(clip)\n",
    "\n",
    "def json2video(json:list, lang = \"cn\", output = \"./cache/video.mp4\"):\n",
    "    videos = []\n",
    "    count = 0;\n",
    "    for l in json:\n",
    "        if l['cg'] != \"\":\n",
    "            #get cg\n",
    "            import wget\n",
    "            wget.download(l['cg'], out=\"./cache/img.png\")\n",
    "            #split text\n",
    "            text = l['summary']\n",
    "            split = text.replace('。','.').split('.')\n",
    "            clips = []\n",
    "            for s in split:\n",
    "                if len(s) > 5:\n",
    "                    count = count + 1;\n",
    "                    clips.append(text2video(text = s, lang = lang, title = l['stage'], prefix = str(count)))\n",
    "            clips = audio_fadein(clips)\n",
    "            videos.append(mpy.concatenate_videoclips(clips, method=\"compose\"))\n",
    "    videos = audio_fadein(videos)\n",
    "    concat_clip = mpy.concatenate_videoclips(videos, method=\"compose\")\n",
    "    concat_clip.write_videofile(output)\n",
    "\n",
    "#output chapter content to html\n",
    "def run(query:str, output = \"./cache/video.mp4\", path=\"../db/cndb\", lang = \"cn\"):\n",
    "    import chromadb\n",
    "    client = chromadb.PersistentClient(path=path)\n",
    "    db = client.get_collection(\"langchain\")\n",
    "    data = db.get()\n",
    "    tmp = []\n",
    "    for k in range(len(data[\"ids\"])):\n",
    "        if query in data[\"metadatas\"][k][\"stage\"]:\n",
    "            this = {\"stage\": data[\"metadatas\"][k][\"stage\"], \n",
    "                    \"summary\": data[\"documents\"][k],\n",
    "                    \"cg\": data[\"metadatas\"][k][\"cg\"],\n",
    "                   }\n",
    "            tmp.append(this);\n",
    "    json2video(json = tmp, lang = lang, output = output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e91e2-fb25-4f11-bd27-5a998d9a2e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  27%|█████████████████▉                                                | 543/1994 [00:26<01:11, 20.28it/s, now=None]"
     ]
    }
   ],
   "source": [
    "run(\"13-22\", lang = \"cn\", path=\"../db/cndb\", output = \"13-22.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c678400f-01db-4af4-a62e-0cb4eceab1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "run(\"13-22\", lang = \"en\",  path=\"../db/arkdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5edec66-86b8-46d8-9634-8882c4a89186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "query = \"13-22\"\n",
    "path=\"../db/cndb\"\n",
    "client = chromadb.PersistentClient(path=path)\n",
    "db = client.get_collection(\"langchain\")\n",
    "data = db.get()\n",
    "tmp = []\n",
    "for k in range(len(data[\"ids\"])):\n",
    "    if query in data[\"metadatas\"][k][\"stage\"]:\n",
    "        this = {\"stage\": data[\"metadatas\"][k][\"stage\"], \n",
    "                \"summary\": data[\"documents\"][k],\n",
    "                \"cg\": data[\"metadatas\"][k][\"cg\"],\n",
    "               }\n",
    "        tmp.append(this);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a108809-b2e2-4310-b9a4-a3cbc1a66de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'故事的第一部分发生在一个帐篷内，有两个人物在对话'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tmp[0]['summary']\n",
    "text.split('。')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1257dc1-9cd1-4224-ac54-6cd9410d9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = text2audio(text.split('。')[0], lang = 'cn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b99d3c1e-c550-4b01-a4fb-7e9ca81d9c17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mAudioArrayClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lang\\Lib\\site-packages\\moviepy\\audio\\AudioClip.py:262\u001b[0m, in \u001b[0;36mAudioArrayClip.__init__\u001b[1;34m(self, array, fps)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[i]\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m make_frame\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnchannels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "AudioArrayClip(res[1], fps=res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e237d07f-6d4f-40ae-b299-a15ae1b8be6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clip \u001b[38;5;241m=\u001b[39m \u001b[43mtext2video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m。\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m clip\u001b[38;5;241m.\u001b[39mwrite_videofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cache/video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n",
      "Cell \u001b[1;32mIn[51], line 16\u001b[0m, in \u001b[0;36mtext2video\u001b[1;34m(text, lang, title)\u001b[0m\n\u001b[0;32m     14\u001b[0m o4 \u001b[38;5;241m=\u001b[39m text2audio(text, lang \u001b[38;5;241m=\u001b[39m lang);\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#audio = mpy.AudioFileClip(target)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mAudioArrayClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo4\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mo4\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#make text\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lang\\Lib\\site-packages\\moviepy\\audio\\AudioClip.py:262\u001b[0m, in \u001b[0;36mAudioArrayClip.__init__\u001b[1;34m(self, array, fps)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[i]\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m make_frame\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnchannels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "clip = text2video(text.split('。')[0],lang='cn',title=tmp[0]['stage'])\n",
    "clip.write_videofile(\"./cache/video.mp4\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae0a681e-e5f0-473b-9ae2-049d2b9524ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from moviepy.audio.AudioClip import AudioArrayClip\n",
    "\n",
    "rate = 44100  # Sampling rate in samples per second.\n",
    "duration = 2  # Duration in seconds\n",
    "\n",
    "data_mono = np.random.uniform(-1, 1, (int(duration*rate/2), 1))\n",
    "\n",
    "audio_mono = AudioArrayClip(data_mono, fps=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84046640-4e0c-483e-be4d-42608cc8e108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.74734869],\n",
       "       [ 0.94559108],\n",
       "       [-0.10485379],\n",
       "       ...,\n",
       "       [-0.52769184],\n",
       "       [ 0.86502881],\n",
       "       [-0.35873155]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "795ea7f6-c462-4ce4-9fc4-41bf282d1936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.8289869e-07, -2.6668969e-05, -1.7760936e-05, ...,\n",
       "        2.4428172e-04,  2.3002260e-04,  2.8541948e-05], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effc739-f34c-4429-93a7-a58ff57df976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
