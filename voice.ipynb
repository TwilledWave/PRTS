{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d0d02a-0400-416d-b877-fbbe3b61000c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint 'pretrained_models/cn/cn.pth' (iteration 876)\n",
      "INFO:root:Loaded checkpoint 'pretrained_models/jp/jp.pth' (iteration 1101)\n",
      "INFO:root:Loaded checkpoint 'pretrained_models/en/en.pth' (iteration 419)\n"
     ]
    }
   ],
   "source": [
    "from models import SynthesizerTrn\n",
    "import sys, os, io\n",
    "import re\n",
    "import argparse\n",
    "import utils\n",
    "import commons\n",
    "import json\n",
    "import torch\n",
    "from text import text_to_sequence, _clean_text\n",
    "from torch import no_grad, LongTensor\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "hps_ms = utils.get_hparams_from_file(r'pretrained_models/config.json')\n",
    "\n",
    "with open(\"pretrained_models/info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    models_info = json.load(f)\n",
    "\n",
    "#load voice model\n",
    "info = models_info['cn']\n",
    "i = 'cn'\n",
    "\n",
    "net_g_ms = SynthesizerTrn(\n",
    "            len(hps_ms.symbols),\n",
    "            hps_ms.data.filter_length // 2 + 1,\n",
    "            hps_ms.train.segment_size // hps_ms.data.hop_length,\n",
    "            n_speakers=hps_ms.data.n_speakers if info['type'] == \"multi\" else 0,\n",
    "            **hps_ms.model)\n",
    "\n",
    "utils.load_checkpoint(f'pretrained_models/{i}/{i}.pth', net_g_ms, None)\n",
    "\n",
    "device = torch.device('cuda') \n",
    "\n",
    "_ = net_g_ms.eval().to(device)\n",
    "\n",
    "sid = info['sid']\n",
    "input_text = \"うふふ……\"\n",
    "lang = 0\n",
    "ns = 0.6\n",
    "nsw = 0.668\n",
    "ls = 1.2\n",
    "symbol_input = True\n",
    "limitation = False\n",
    "\n",
    "def get_text(text, hps, is_symbol):\n",
    "    text_norm = text_to_sequence(text, hps.symbols, [] if is_symbol else hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = LongTensor(text_norm)\n",
    "    return text_norm\n",
    "\n",
    "def create_tts_fn(net_g_ms, speaker_id, hps_ms):\n",
    "    def tts_fn(text, language, noise_scale, noise_scale_w, length_scale, is_symbol):\n",
    "        text = text.replace('\\n', ' ').replace('\\r', '').replace(\" \", \"\")\n",
    "        if limitation:\n",
    "            text_len = len(re.sub(\"\\[([A-Z]{2})\\]\", \"\", text))\n",
    "            max_len = 100\n",
    "            if is_symbol:\n",
    "                max_len *= 3\n",
    "            if text_len > max_len:\n",
    "                return \"Error: Text is too long\", None\n",
    "        if not is_symbol:\n",
    "            if language == 0:\n",
    "                text = f\"[ZH]{text}[ZH]\"\n",
    "            elif language == 1:\n",
    "                text = f\"[JA]{text}[JA]\"\n",
    "            else:\n",
    "                text = f\"[EN]{text}[EN]\"\n",
    "        stn_tst = get_text(text, hps_ms, is_symbol)\n",
    "        with no_grad():\n",
    "            x_tst = stn_tst.unsqueeze(0).to(device)\n",
    "            x_tst_lengths = LongTensor([stn_tst.size(0)]).to(device)\n",
    "            sid = LongTensor([speaker_id]).to(device)\n",
    "            audio = net_g_ms.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=noise_scale, noise_scale_w=noise_scale_w,\n",
    "                                   length_scale=length_scale)[0][0, 0].data.cpu().float().numpy()\n",
    "\n",
    "        return \"Success\", (22050, audio)\n",
    "    return tts_fn\n",
    "\n",
    "def create_to_symbol_fn(hps):\n",
    "    def to_symbol_fn(is_symbol_input, input_text, temp_lang):\n",
    "        if temp_lang == 0:\n",
    "            clean_text = f'[ZH]{input_text}[ZH]'\n",
    "        elif temp_lang == 1:\n",
    "            clean_text = f'[JA]{input_text}[JA]'\n",
    "        else:\n",
    "            clean_text = f'[EN]{input_text}[EN]'\n",
    "        return _clean_text(clean_text, hps.data.text_cleaners) if is_symbol_input else ''\n",
    "\n",
    "    return to_symbol_fn\n",
    "\n",
    "def change_lang(language):\n",
    "    if language == 0:\n",
    "        return 0.6, 0.668, 1.2\n",
    "    elif language == 1:\n",
    "        return 0.6, 0.668, 1\n",
    "    else:\n",
    "        return 0.6, 0.668, 1\n",
    "\n",
    "tts_fn_eula = create_tts_fn(net_g_ms, sid, hps_ms)\n",
    "#o1, o2 = tts_fn(input_text, lang,  ns, nsw, ls, symbol_input)\n",
    "#write('test.wav',o2[0],o2[1])\n",
    "\n",
    "def tts_fn_cn(input_text):\n",
    "    lang = 0\n",
    "    ns = 0.6\n",
    "    nsw = 0.668\n",
    "    ls = 1.3\n",
    "    symbol_input = False\n",
    "    limitation = False\n",
    "    return tts_fn_eula(input_text, lang,  ns, nsw, ls, symbol_input)\n",
    "\n",
    "import ctypes\n",
    "from ctypes import *\n",
    "from ctypes import wintypes as w\n",
    "dll = WinDLL('winmm')\n",
    "dll.PlaySoundW.argtypes = w.LPCWSTR,w.HMODULE,w.DWORD\n",
    "dll.PlaySoundW.restype = w.BOOL\n",
    "SND_FILENAME = 0x20000\n",
    "#dll.PlaySoundW('test.wav',None,SND_FILENAME)\n",
    "\n",
    "\n",
    "#load 2nd voice model\n",
    "info = models_info['jp']\n",
    "i = 'jp'\n",
    "\n",
    "net_g_ms = SynthesizerTrn(\n",
    "            len(hps_ms.symbols),\n",
    "            hps_ms.data.filter_length // 2 + 1,\n",
    "            hps_ms.train.segment_size // hps_ms.data.hop_length,\n",
    "            n_speakers=hps_ms.data.n_speakers if info['type'] == \"multi\" else 0,\n",
    "            **hps_ms.model)\n",
    "\n",
    "utils.load_checkpoint(f'pretrained_models/{i}/{i}.pth', net_g_ms, None)\n",
    "device = torch.device('cuda') \n",
    "_ = net_g_ms.eval().to(device)\n",
    "\n",
    "sid = info['sid']\n",
    "tts_fn_ayaka = create_tts_fn(net_g_ms, sid, hps_ms)\n",
    "\n",
    "def tts_fn_jp(input_text):\n",
    "    lang = 1\n",
    "    ns = 0.6\n",
    "    nsw = 0.668\n",
    "    ls = 1.0\n",
    "    symbol_input = False\n",
    "    limitation = False\n",
    "    return tts_fn_ayaka(input_text, lang,  ns, nsw, ls, symbol_input)\n",
    "\n",
    "#o3, o4 = tts_fn_jp(\"はい,ご主人様\")\n",
    "#write('chat.wav',o4[0],o4[1])\n",
    "\n",
    "#load 3rd EN voice model\n",
    "hps_ms2 = utils.get_hparams_from_file(r'pretrained_models/trilingual.json')\n",
    "\n",
    "info = models_info['en']\n",
    "i = 'en'\n",
    "\n",
    "net_g_ms2 = SynthesizerTrn(\n",
    "            len(hps_ms2.symbols),\n",
    "            hps_ms2.data.filter_length // 2 + 1,\n",
    "            hps_ms2.train.segment_size // hps_ms.data.hop_length,\n",
    "            n_speakers=hps_ms2.data.n_speakers if info['type'] == \"multi\" else 0,\n",
    "            **hps_ms2.model)\n",
    "\n",
    "utils.load_checkpoint(f'pretrained_models/{i}/{i}.pth', net_g_ms2, None)\n",
    "device = torch.device('cuda') \n",
    "_ = net_g_ms2.eval().to(device)\n",
    "\n",
    "sid = info['sid']\n",
    "tts_fn_raiden = create_tts_fn(net_g_ms2, sid, hps_ms2)\n",
    "\n",
    "def tts_fn_en(input_text):\n",
    "    lang = 2\n",
    "    ns = 0.6\n",
    "    nsw = 0.668\n",
    "    ls = 1.0\n",
    "    symbol_input = False\n",
    "    limitation = False\n",
    "    return tts_fn_raiden(input_text, lang,  ns, nsw, ls, symbol_input)\n",
    "\n",
    "def tts_fn(input_text, lang = 'en'):\n",
    "    ns = 0.6\n",
    "    nsw = 0.668\n",
    "    ls = 1.0\n",
    "    symbol_input = False\n",
    "    limitation = False    \n",
    "    if lang == 'en':\n",
    "        ls = 1.25\n",
    "        ns = 0.667\n",
    "        nsw = 0.8\n",
    "        return tts_fn_raiden(input_text, 2,  ns, nsw, ls, symbol_input)\n",
    "    elif lang == 'jp':\n",
    "        return tts_fn_ayaka(input_text, 1,  ns, nsw, ls, symbol_input)\n",
    "    elif lang == 'cn':\n",
    "        ls = 1.4\n",
    "        return tts_fn_eula(input_text, 0,  ns, nsw, ls, symbol_input)\n",
    "\n",
    "#EN voice\n",
    "\n",
    "#from TTS.api import TTS\n",
    "##disable logging\n",
    "#import logging\n",
    "#logging.disable(logging.CRITICAL)\n",
    "\n",
    "#text_trap = io.StringIO()\n",
    "#sys.stdout = text_trap\n",
    "\n",
    "# List available 🐸TTS models and choose the first one\n",
    "#model_name = TTS.list_models()[0]\n",
    "# Init TTS\n",
    "#tts = TTS(\"tts_models/en/ljspeech/tacotron2-DDC_ph\", gpu = True)\n",
    "\n",
    "#sys.stdout = sys.__stdout__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a409fa78-95a8-4272-8fab-480c95fff78b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"the story is about how Infectors are discriminated against and how the knights work for justice and equality\" ; text = \"现在我处于高潮中的状态，我的小穴在蠢蠢欲动\"\n",
    "text3 = \"高雄型重巡洋艦二番艦、第二艦隊旗艦の愛宕よ。私の元で結構多くの姉妹たちが戦っていたもの。どんな任務でもお姉さんに任せてね。うふふ……\"\n",
    "o3, o4 = tts_fn(text2, 'en')\n",
    "write('chat.wav',o4[0],o4[1])\n",
    "dll.PlaySoundW('chat.wav',None,SND_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199be1d1-c47f-4901-8b22-4d867ddbc414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41451369-741a-4521-96fc-a87dae01212b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
